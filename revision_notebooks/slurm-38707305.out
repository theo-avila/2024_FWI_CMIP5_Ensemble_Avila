2025-05-24 19:44:08,914 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.1.174:34639'
2025-05-24 19:44:11,130 - distributed.worker - INFO -       Start worker at:     tcp://10.6.1.174:41789
2025-05-24 19:44:11,131 - distributed.worker - INFO -          Listening to:     tcp://10.6.1.174:41789
2025-05-24 19:44:11,131 - distributed.worker - INFO -           Worker name:             SLURMCluster-1
2025-05-24 19:44:11,131 - distributed.worker - INFO -          dashboard at:           10.6.1.174:38517
2025-05-24 19:44:11,131 - distributed.worker - INFO - Waiting to connect to: tcp://146.186.150.11:40059
2025-05-24 19:44:11,131 - distributed.worker - INFO - -------------------------------------------------
2025-05-24 19:44:11,131 - distributed.worker - INFO -               Threads:                          1
2025-05-24 19:44:11,131 - distributed.worker - INFO -                Memory:                 100.00 GiB
2025-05-24 19:44:11,131 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ltluqu5a
2025-05-24 19:44:11,131 - distributed.worker - INFO - -------------------------------------------------
2025-05-24 19:44:11,174 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-05-24 19:44:11,175 - distributed.worker - INFO -         Registered to: tcp://146.186.150.11:40059
2025-05-24 19:44:11,175 - distributed.worker - INFO - -------------------------------------------------
2025-05-24 19:44:11,175 - distributed.core - INFO - Starting established connection to tcp://146.186.150.11:40059
2025-05-24 19:59:42,397 - distributed.worker - ERROR - Compute Failed
Key:       model_climatology-f331d895-bfd4-45d9-afd2-ae274a4f173f
State:     long-running
Task:  <Task 'model_climatology-f331d895-bfd4-45d9-afd2-ae274a4f173f' model_climatology(...)>
Exception: 'AttributeError("\'DataArrayGroupBy\' object has no attribute \'windspeed\'")'
Traceback: '  File "/tmp/ipykernel_2988808/3487329287.py", line 31, in model_climatology\n'

2025-05-24 20:23:44,788 - distributed.worker - ERROR - Compute Failed
Key:       ('open_dataset-original-concatenate-68293749a5179ba817333fcf33f6c468', 6, 0, 0)
State:     executing
Task:  <Task ('open_dataset-original-concatenate-68293749a5179ba817333fcf33f6c468', 6, 0, 0) _execute_subgraph(...)>
Exception: "RuntimeError('NetCDF: HDF error')"
Traceback: '  File "/storage/work/cta5244/.conda/envs/fwi_env/lib/python3.10/site-packages/dask/array/core.py", line 141, in getter\n    c = np.asarray(c)\n  File "/storage/work/cta5244/.conda/envs/fwi_env/lib/python3.10/site-packages/xarray/core/indexing.py", line 575, in __array__\n    return np.asarray(self.get_duck_array(), dtype=dtype, copy=copy)\n  File "/storage/work/cta5244/.conda/envs/fwi_env/lib/python3.10/site-packages/xarray/core/indexing.py", line 580, in get_duck_array\n    return self.array.get_duck_array()\n  File "/storage/work/cta5244/.conda/envs/fwi_env/lib/python3.10/site-packages/xarray/core/indexing.py", line 791, in get_duck_array\n    return self.array.get_duck_array()\n  File "/storage/work/cta5244/.conda/envs/fwi_env/lib/python3.10/site-packages/xarray/core/indexing.py", line 654, in get_duck_array\n    array = self.array[self.key]\n  File "/storage/work/cta5244/.conda/envs/fwi_env/lib/python3.10/site-packages/xarray/backends/netCDF4_.py", line 103, in __getitem__\n    return indexing.explicit_indexing_adapter(\n  File "/storage/work/cta5244/.conda/envs/fwi_env/lib/python3.10/site-packages/xarray/core/indexing.py", line 1015, in explicit_indexing_adapter\n    result = raw_indexing_method(raw_key.tuple)\n  File "/storage/work/cta5244/.conda/envs/fwi_env/lib/python3.10/site-packages/xarray/backends/netCDF4_.py", line 116, in _getitem\n    array = getitem(original_array, key)\n  File "src/netCDF4/_netCDF4.pyx", line 5079, in netCDF4._netCDF4.Variable.__getitem__\n  File "src/netCDF4/_netCDF4.pyx", line 6051, in netCDF4._netCDF4.Variable._get\n  File "src/netCDF4/_netCDF4.pyx", line 2164, in netCDF4._netCDF4._ensure_nc_success\n'

